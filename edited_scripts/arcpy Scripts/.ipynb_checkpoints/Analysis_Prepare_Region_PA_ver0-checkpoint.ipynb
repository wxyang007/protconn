{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "import os.path\n",
    "import arcpy.cartography as CA\n",
    "arcpy.env.overwriteOutput = True\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bufferPA(region_file, region_relevant, PA_file, PA_relevant, PAonly_relevant, PA_relevant_buffer, region_code):\n",
    "    # Process: Select analysis\n",
    "    arcpy.Select_analysis(region_file, region_relevant, \"STATEFP = '%s'\" % region_code, )\n",
    "    # Process: Clip PA by region\n",
    "    arcpy.analysis.Clip(PA_file, region_relevant, PA_relevant, \"#\")\n",
    "    # Process: Select only PAs\n",
    "    arcpy.Select_analysis(PA_relevant, PAonly_relevant, \"ifPA = '1'\",)\n",
    "    # Process: Buffer\n",
    "    arcpy.Buffer_analysis(PAonly_relevant, PA_relevant_buffer, \"230 kilometers\", \"FULL\", \"ROUND\", \"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRef(PAonly_relevant, PA_relevant_dissolved, PA_relevant_ds_gcs):\n",
    "    # Process: Dissolve\n",
    "    arcpy.Dissolve_management(PAonly_relevant, PA_relevant_dissolved)\n",
    "\n",
    "    gcs = arcpy.SpatialReference(\"WGS 1984\")\n",
    "    # Process: Project to a geographic coordinate system\n",
    "    arcpy.management.Project(PA_relevant_dissolved, PA_relevant_ds_gcs, gcs)\n",
    "    # Process: Calculate geometry field lon and lat\n",
    "    arcpy.CalculateGeometryAttributes_management(PA_relevant_ds_gcs, [[\"lon\",\"CENTROID_X\"],\n",
    "                                                          [\"lat\",\"CENTROID_Y\"]])\n",
    "    lon = arcpy.da.SearchCursor(PA_relevant_ds_gcs, (\"lon\",)).next()[0]\n",
    "    lat = arcpy.da.SearchCursor(PA_relevant_ds_gcs, (\"lat\",)).next()[0]\n",
    "    wkt = \"PROJCS['World_Azimuthal_Equidistant',\\\n",
    "           GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],\\\n",
    "           PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]],\\\n",
    "           PROJECTION['Azimuthal_Equidistant'],\\\n",
    "           PARAMETER['False_Easting',0.0],\\\n",
    "           PARAMETER['False_Northing',0.0],\\\n",
    "           PARAMETER['Central_Meridian',{0}],\\\n",
    "           PARAMETER['Latitude_Of_Origin',{1}],\\\n",
    "           UNIT['Meter',1.0]]\".format(str(lon), str(lat))\n",
    "    azimuthal_sr = arcpy.SpatialReference(text=wkt)\n",
    "    return azimuthal_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutput(PA_relevant_buffered_azimuthal, PA_final, outpath, tab_final):\n",
    "    # Process: Add Field nodeID\n",
    "    arcpy.AddField_management(PA_relevant_buffered_azimuthal, \"nodeID\", \"LONG\", \"\", \"\", \"\", \"\", \"NULLABLE\", \"NON_REQUIRED\", \"\")\n",
    "\n",
    "    # Process: Calculate Field\n",
    "    arcpy.CalculateField_management(PA_relevant_buffered_azimuthal, \"nodeID\", \"!OBJECTID!\", \"PYTHON\", \"\")\n",
    "    print(\"Field nodeID computed\")\n",
    "\n",
    "    # Process: Copy Features (2)\n",
    "    arcpy.CopyFeatures_management(PA_relevant_buffered_azimuthal, PA_final, \"\", \"0\", \"0\", \"0\")\n",
    "    print(\"Final layer copied\")\n",
    "    \n",
    "    # Table to table (txt) with field mapping (in alternative to copy rows)\n",
    "    arcpy.TableToTable_conversion(in_rows=PA_final, out_path=outpath, out_name=tab_final)\n",
    "    print(\"Attribute Table exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input setting\n",
    "#--input files of region--\n",
    "region_folder = r'C:\\Users\\ywx12\\Desktop\\PhD\\RA\\ProtectedLand\\ProtConn_CALC\\data\\REGION\\Counties\\tl_2020_us_county'\n",
    "region_file = region_folder + '/tl_2020_us_county2state_proj.shp'\n",
    "region_abbr_file = r'C:\\Users\\ywx12\\Desktop\\PhD\\RA\\ProtectedLand\\ProtConn_CALC\\data\\REGION\\Counties\\states_fp_name.csv'\n",
    "regionname = 'STATE'\n",
    "region_abbr_df = pd.read_csv(region_abbr_file)\n",
    "#--input file of PA--\n",
    "ingdb_fullpath = r\"C:\\Users\\ywx12\\Desktop\\PhD\\RA\\ProtectedLand\\ProtConn_CALC\\data\\ProtConn_July2021_1.gdb\"\n",
    "PA_file = ingdb_fullpath + '\\PA_mexcanus_final_' + regionname\n",
    "\n",
    "# Output setting\n",
    "outgdb_folder = r\"C:\\Users\\ywx12\\Desktop\\PhD\\RA\\ProtectedLand\\ProtConn_CALC\\data\"\n",
    "outgdb_name = 'States_PA_1.gdb'\n",
    "outgdb_fullpath = r\"C:\\Users\\ywx12\\Desktop\\PhD\\RA\\ProtectedLand\\ProtConn_CALC\\data\\States_PA_1.gdb\"\n",
    "outpath = r'C:\\Users\\ywx12\\Desktop\\PhD\\RA\\ProtectedLand\\ProtConn_CALC\\data\\REGION_PA\\STATES_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outgdb already exists.\n"
     ]
    }
   ],
   "source": [
    "# Process: Create GDB\n",
    "if arcpy.Exists(outgdb_fullpath):\n",
    "    print(\"outgdb already exists.\")\n",
    "else:\n",
    "    arcpy.CreateFileGDB_management(outgdb_folder, outgdb_name)\n",
    "    print(\"outgdb created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediate Files\n",
    "PA_relevant = outgdb_fullpath + '/PA_relevant'\n",
    "PAonly_relevant = outgdb_fullpath + '/PAonly_relevant'\n",
    "\n",
    "PA_relevant_dissolved = outgdb_fullpath + '/PA_relevant_dissolved'\n",
    "# PA_relevant_pt = outgdb_fullpath + '/PA_relevant_pt'\n",
    "PA_relevant_ds_gcs = outgdb_fullpath + '/PA_relevant_ds_gcs'\n",
    "\n",
    "PA_relevant_buffer = outgdb_fullpath + '/PA_relevant_buffer'\n",
    "\n",
    "region_relevant = outgdb_fullpath + '/region_relevant'\n",
    "region_relevant_azimuthal = outgdb_fullpath + '/region_relevant_azimuthal'\n",
    "\n",
    "PA_relevant_buffered = outgdb_fullpath + '/PA_relevant_buffered'\n",
    "PA_relevant_buffered_azimuthal = outgdb_fullpath + '/PA_relevant_buffered_azimuthal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start working on:  Alabama\n",
      "Start working on:  Alaska\n",
      "Start working on:  Arizona\n",
      "Start working on:  Arkansas\n",
      "Start working on:  California\n",
      "Start working on:  Colorado\n",
      "Start working on:  Connecticut\n",
      "Start working on:  Delaware\n",
      "Start working on:  District of Columbia\n",
      "Start working on:  Florida\n",
      "Start working on:  Georgia\n",
      "Start working on:  Hawaii\n",
      "Start working on:  Idaho\n",
      "Start working on:  Illinois\n",
      "Start working on:  Indiana\n",
      "Start working on:  Iowa\n",
      "Start working on:  Kansas\n",
      "Start working on:  Kentucky\n",
      "Start working on:  Louisiana\n",
      "Start working on:  Maine\n",
      "Start working on:  Maryland\n",
      "Start working on:  Massachusetts\n",
      "Start working on:  Michigan\n",
      "Start working on:  Minnesota\n",
      "Start working on:  Mississippi\n",
      "Start working on:  Missouri\n",
      "Start working on:  Montana\n",
      "Start working on:  Nebraska\n",
      "Start working on:  Nevada\n",
      "Start working on:  New Hampshire\n",
      "Start working on:  New Jersey\n",
      "Start working on:  New Mexico\n",
      "Start working on:  New York\n",
      "Start working on:  North Carolina\n",
      "Start working on:  North Dakota\n",
      "Start working on:  Ohio\n",
      "Start working on:  Oklahoma\n",
      "Start working on:  Oregon\n",
      "Start working on:  Pennsylvania\n",
      "Start working on:  Rhode Island\n",
      "Start working on:  South Carolina\n",
      "Start working on:  South Dakota\n",
      "Start working on:  Tennessee\n",
      "Start working on:  Texas\n",
      "Start working on:  Utah\n",
      "Start working on:  Vermont\n",
      "Start working on:  Virginia\n",
      "Start working on:  Washington\n",
      "Field nodeID computed\n",
      "Final layer copied\n",
      "Attribute Table exported\n",
      "Washington finished, total time elapsed: 0.83\n",
      "Start working on:  West Virginia\n",
      "Field nodeID computed\n",
      "Final layer copied\n",
      "Attribute Table exported\n",
      "West Virginia finished, total time elapsed: 0.84\n",
      "Start working on:  Wisconsin\n",
      "Field nodeID computed\n",
      "Final layer copied\n",
      "Attribute Table exported\n",
      "Wisconsin finished, total time elapsed: 1.05\n",
      "Start working on:  Wyoming\n",
      "Field nodeID computed\n",
      "Final layer copied\n",
      "Attribute Table exported\n",
      "Wyoming finished, total time elapsed: 0.71\n",
      "Start working on:  American Samoa\n",
      "Start working on:  Guam\n",
      "Start working on:  Northern Mariana Islands\n",
      "Start working on:  Puerto Rico\n",
      "Field nodeID computed\n",
      "Final layer copied\n",
      "Attribute Table exported\n",
      "Puerto Rico finished, total time elapsed: 0.42\n",
      "Start working on:  U.S. Virgin Islands\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(region_abbr_df)):\n",
    "    try:\n",
    "        region_code = str(region_abbr_df.iloc[i][1])\n",
    "        if len(region_code) == 1:\n",
    "            region_code = '0' + region_code\n",
    "        region_abbr = region_abbr_df.iloc[i][2]\n",
    "        target_region = region_abbr_df.iloc[i][3]\n",
    "        print('Start working on: ', target_region)\n",
    "        time0 = time.time()\n",
    "\n",
    "        for j in [PA_relevant, PAonly_relevant, PA_relevant_dissolved,\n",
    "              PA_relevant_ds_gcs, PA_relevant_buffer, \n",
    "              region_relevant, region_relevant_azimuthal,\n",
    "              PA_relevant_buffered, PA_relevant_buffered_azimuthal]:\n",
    "            if arcpy.Exists(j):\n",
    "                arcpy.Delete_management(j)\n",
    "\n",
    "        # outfiles\n",
    "        PA_final = outpath + '/PA_230km_' + region_abbr + '_July2021.shp'\n",
    "        tab_final = 'PA_230km_' + region_abbr + '_July2021.txt'\n",
    "        \n",
    "        if arcpy.Exists(PA_final):\n",
    "            pass\n",
    "        else:\n",
    "            bufferPA(region_file, region_relevant, PA_file, PA_relevant, PAonly_relevant, PA_relevant_buffer, region_code)\n",
    "\n",
    "            azimuthal_sr = getRef(PAonly_relevant, PA_relevant_dissolved, PA_relevant_ds_gcs)\n",
    "\n",
    "            # Process: Clip\n",
    "            arcpy.analysis.Clip(PA_file, PA_relevant_buffer, PA_relevant_buffered, \"#\")\n",
    "\n",
    "            # Process: Project to azimuthal equidistant projection\n",
    "            arcpy.management.Project(PA_relevant_buffered, PA_relevant_buffered_azimuthal, azimuthal_sr)\n",
    "\n",
    "            # Process: Repair Geometry\n",
    "            arcpy.RepairGeometry_management(PA_relevant_buffered_azimuthal, \"DELETE_NULL\")\n",
    "\n",
    "            getOutput(PA_relevant_buffered_azimuthal, PA_final, outpath, tab_final)\n",
    "\n",
    "            time1 = time.time()\n",
    "            totaltime = (time1-time0)/60\n",
    "            print(target_region + ' finished, total time elapsed: ' +  \"{:.2f}\".format(totaltime))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
